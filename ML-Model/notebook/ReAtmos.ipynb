{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCd91EMJTRm5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1768844823157,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "c1ba5116",
    "outputId": "c2bcb4c1-dad3-42dc-e6c6-b20cc6508116"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"30-04-2025\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bihar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Purnia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_of_monitoring_stations\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prominent_pollutants\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"CO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aqi_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 56,\n        \"max\": 103,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"air_quality_status\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"number_of_monitoring_stations in Absolute Number, aqi_value in Indices\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"note\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-bdefc723-d3b8-4d33-8c5b-26aebd968a74\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>area</th>\n",
       "      <th>number_of_monitoring_stations</th>\n",
       "      <th>prominent_pollutants</th>\n",
       "      <th>aqi_value</th>\n",
       "      <th>air_quality_status</th>\n",
       "      <th>unit</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30-04-2025</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Amravati</td>\n",
       "      <td>2</td>\n",
       "      <td>PM10</td>\n",
       "      <td>78</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>number_of_monitoring_stations in Absolute Numb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-04-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purnia</td>\n",
       "      <td>1</td>\n",
       "      <td>CO</td>\n",
       "      <td>56</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>number_of_monitoring_stations in Absolute Numb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-04-2025</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>Katni</td>\n",
       "      <td>1</td>\n",
       "      <td>O3</td>\n",
       "      <td>98</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>number_of_monitoring_stations in Absolute Numb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30-04-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Tumidih</td>\n",
       "      <td>1</td>\n",
       "      <td>PM10</td>\n",
       "      <td>103</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>number_of_monitoring_stations in Absolute Numb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30-04-2025</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Byrnihat</td>\n",
       "      <td>1</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>61</td>\n",
       "      <td>Satisfactory</td>\n",
       "      <td>number_of_monitoring_stations in Absolute Numb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdefc723-d3b8-4d33-8c5b-26aebd968a74')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bdefc723-d3b8-4d33-8c5b-26aebd968a74 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bdefc723-d3b8-4d33-8c5b-26aebd968a74');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         date           state      area  number_of_monitoring_stations  \\\n",
       "0  30-04-2025     Maharashtra  Amravati                              2   \n",
       "1  30-04-2025           Bihar    Purnia                              1   \n",
       "2  30-04-2025  Madhya Pradesh     Katni                              1   \n",
       "3  30-04-2025    Chhattisgarh   Tumidih                              1   \n",
       "4  30-04-2025           Assam  Byrnihat                              1   \n",
       "\n",
       "  prominent_pollutants  aqi_value air_quality_status  \\\n",
       "0                 PM10         78       Satisfactory   \n",
       "1                   CO         56       Satisfactory   \n",
       "2                   O3         98       Satisfactory   \n",
       "3                 PM10        103           Moderate   \n",
       "4                PM2.5         61       Satisfactory   \n",
       "\n",
       "                                                unit  note  \n",
       "0  number_of_monitoring_stations in Absolute Numb...   NaN  \n",
       "1  number_of_monitoring_stations in Absolute Numb...   NaN  \n",
       "2  number_of_monitoring_stations in Absolute Numb...   NaN  \n",
       "3  number_of_monitoring_stations in Absolute Numb...   NaN  \n",
       "4  number_of_monitoring_stations in Absolute Numb...   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('aqi.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1768845032864,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "V528FoK8XgYT",
    "outputId": "deddff7a-7113-4688-bcc4-ec6a9b2330b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maharashtra' 'Bihar' 'Madhya Pradesh' 'Chhattisgarh' 'Assam' 'Manipur'\n",
      " 'Kerala' 'West Bengal' 'Odisha' 'Karnataka' 'Gujarat' 'Uttarakhand'\n",
      " 'Tamil Nadu' 'Andhra Pradesh' 'Rajasthan' 'Uttar Pradesh' 'Punjab'\n",
      " 'Mizoram' 'Chandigarh' 'Telangana' 'Puducherry' 'Meghalaya'\n",
      " 'Himachal Pradesh' 'Jharkhand' 'Haryana' 'Arunachal Pradesh' 'Nagaland'\n",
      " 'Tripura' 'Delhi' 'Andaman and Nicobar Islands' 'Sikkim'\n",
      " 'Jammu and Kashmir']\n",
      "\n",
      "\n",
      "states 32\n",
      "\n",
      "\n",
      "['Amravati' 'Purnia' 'Katni' 'Tumidih' 'Byrnihat' 'Imphal' 'Kollam'\n",
      " 'Barrackpore' 'Nayagarh' 'Nalbari' 'Hubballi' 'Ahmedabad' 'Dehradun'\n",
      " 'Vellore' 'Ulhasnagar' 'Chengalpattu' 'Tirupati' 'Dindigul' 'Kadapa'\n",
      " 'Thane' 'Rishikesh' 'Raipur' 'Ranipet' 'Samastipur' 'Jabalpur'\n",
      " 'Kishanganj' 'Saharsa' 'Yadgir' 'Dungarpur' 'Meerut' 'Sawai Madhopur'\n",
      " 'Ghaziabad' 'Pithampur' 'Kanpur' 'Chennai' 'Nagaur' 'Chittoor' 'Kalyan'\n",
      " 'Mira Bhayandar' 'Bhubaneswar' 'Churu' 'Jodhpur' 'Katihar' 'Pali'\n",
      " 'Balasore' 'Sikar' 'Jalandhar' 'Tirumala' 'Angul' 'Patiala'\n",
      " 'Pimpri Chinchwad' 'Vatva' 'Chamarajanagar' 'Jaisalmer' 'Keonjhar'\n",
      " 'Chittorgarh' 'Chikkaballapur' 'Bhilwara' 'Arrah' 'Agra' 'Kota'\n",
      " 'Chikkamagaluru' 'Bharatpur' 'Aizawl' 'Gandhi Nagar' 'Dausa' 'Kunjemura'\n",
      " 'Motihari' 'Ujjain' 'Salem' 'Vijayawada' 'Thoothukudi' 'Davanagere'\n",
      " 'Coimbatore' 'Bhiwadi' 'NOIDA' 'Parbhani' 'Vrindavan' 'Bagalkot'\n",
      " 'Chandigarh' 'Cuddalore' 'Barmer' 'Tonk' 'Bareilly' 'Baran' 'Korba'\n",
      " 'Rajsamand' 'Firozabad' 'Aurangabad' 'Greater Noida' 'Guwahati'\n",
      " 'Pratapgarh' 'Kolkata' 'Jalna' 'Dhule' 'Hyderabad' 'Puducherry' 'Khurja'\n",
      " 'Bundi' 'Bengaluru' 'Latur' 'Solapur' 'Howrah' 'Jhansi' 'Muzaffarpur'\n",
      " 'Siliguri' 'Ratlam' 'Silchar' 'Thrissur' 'Ludhiana' 'Bettiah' 'Thanjavur'\n",
      " 'Nagpur' 'Bulandshahr' 'Shillong' 'Haldia' 'Talcher' 'Baddi' 'Kalaburagi'\n",
      " 'Araria' 'Belapur' 'Manguraha' 'Bathinda' 'Ramanathapuram' 'Namakkal'\n",
      " 'Madikeri' 'Tiruppur' 'Akola' 'Udaipur' 'Hapur' 'Dharwad' 'Dhanbad'\n",
      " 'Rajamahendravaram' 'Jhunjhunu' 'Baghpat' 'Belgaum' 'Surat' 'Gurugram'\n",
      " 'Sirohi' 'Asansol' 'Visakhapatnam' 'Nagapattinam' 'Prayagraj' 'Gorakhpur'\n",
      " 'Bhiwandi' 'Byasanagar' 'Begusarai' 'Mumbai' 'Boisar' 'Hosur' 'Siwan'\n",
      " 'Anantapur' 'Kolhapur' 'Khanna' 'Naharlagun' 'Jalore' 'Dholpur' 'Bikaner'\n",
      " 'Madurai' 'Indore' 'Muzaffarnagar' 'Kanchipuram' 'Sagar' 'Virar'\n",
      " 'Hajipur' 'Jaipur' 'Nagaon' 'Kashipur' 'Amaravati' 'Pudukottai' 'Munger'\n",
      " 'Karauli' 'Buxar' 'Chandrapur' 'Malegaon' 'Palkalaiperur'\n",
      " 'Sri Ganganagar' 'Navi Mumbai' 'Bhopal' 'Rourkela' 'Jhalawar' 'Gwalior'\n",
      " 'Suakati' 'Tirunelveli' 'Ahmednagar' 'Moradabad' 'Lucknow' 'Ajmer' 'Gaya'\n",
      " 'Gummidipoondi' 'Mahad' 'Jalgaon' 'Bhilai' 'Eloor' 'Sivasagar' 'Pune'\n",
      " 'Kohima' 'Ariyalur' 'Shivamogga' 'Dewas' 'Bhagalpur' 'Agartala' 'Nanded'\n",
      " 'Varanasi' 'Banswara' 'Panchgaon' 'Nashik' 'Badlapur' 'Baripada' 'Delhi'\n",
      " 'Cuttack' 'Sangli' 'Damoh' 'Ooty' 'Ramanagara' 'Koppal' 'Sasaram'\n",
      " 'Ankleshwar' 'Singrauli' 'Durgapur' 'Patna' 'Brajrajnagar'\n",
      " 'Thiruvananthapuram' 'Barbil' 'Alwar' 'Vapi' 'Rajgir' 'Mandideep'\n",
      " 'Rairangpur' 'Tiruchirappalli' 'Sri Vijaya Puram' 'Bidar' 'Tensa'\n",
      " 'Mysuru' 'Bilaspur' 'Haveri' 'Chhapra' 'Kannur' 'Chhal' 'Hanumangarh'\n",
      " 'Mandi Gobindgarh' 'Milupara' 'Gadag' 'Virudhunagar' 'Bileipada' 'Maihar'\n",
      " 'Mangalore' 'Amritsar' 'Satna' 'Rupnagar' 'Karur' 'Gangtok' 'Tumakuru'\n",
      " 'Bihar Sharif' 'Nandesari' 'Faridabad' 'Charkhi Dadri' 'Karwar' 'Hassan'\n",
      " 'Kolar' 'Udupi' 'Raichur' 'Vijayapura' 'Panchkula' 'Rohtak' 'Jorapokhar'\n",
      " 'Palwal' 'Ballabgarh' 'Yamunanagar' 'Kaithal' 'Ambala' 'Sonipat'\n",
      " 'Manesar' 'Karnal' 'Fatehabad' 'Kurukshetra' 'Mandikhera' 'Sirsa'\n",
      " 'Panipat' 'Bhiwani' 'Dharuhera' 'Jind' 'Bahadurgarh' 'Hisar' 'Narnaul'\n",
      " 'Pathardih' 'Kochi' 'Srinagar' 'Kozhikode' 'Darbhanga' 'Ernakulam']\n",
      "\n",
      "\n",
      "areas 291\n"
     ]
    }
   ],
   "source": [
    "print(df['state'].unique())\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f'states {len(df['state'].unique())}')\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(df['area'].unique())\n",
    "\n",
    "print()\n",
    "print()\n",
    "print(f'areas {len(df['area'].unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1768845576613,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "2u8W6jwhXpl4",
    "outputId": "25130ea7-a58d-46a6-d321-f8b05139f4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gujarat :                 area\n",
      "11         Ahmedabad\n",
      "51             Vatva\n",
      "64      Gandhi Nagar\n",
      "137            Surat\n",
      "218       Ankleshwar\n",
      "...              ...\n",
      "235639         Vatva\n",
      "235663     Nandesari\n",
      "235685    Ankleshwar\n",
      "235694  Gandhi Nagar\n",
      "235744     Ahmedabad\n",
      "\n",
      "[6215 rows x 1 columns]\n",
      "Karnataka :                   area\n",
      "10            Hubballi\n",
      "27              Yadgir\n",
      "52      Chamarajanagar\n",
      "56      Chikkaballapur\n",
      "61      Chikkamagaluru\n",
      "...                ...\n",
      "235759        Bagalkot\n",
      "235763        Madikeri\n",
      "235767          Mysuru\n",
      "235773      Kalaburagi\n",
      "235774          Koppal\n",
      "\n",
      "[23494 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f'Gujarat : {df.loc[df['state'] == 'Gujarat', ['area']]}')\n",
    "print(f'Karnataka : {df.loc[df['state'] == 'Karnataka', ['area']]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1768845646026,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "BXUPkqtrZBxH",
    "outputId": "2501b841-de9e-4cb2-bd09-65b108e09e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Andaman and Nicobar Islands': ['Sri Vijaya Puram'], 'Andhra Pradesh': ['Chittoor', 'Vijayawada', 'Anantapur', 'Tirumala', 'Rajamahendravaram', 'Amaravati', 'Visakhapatnam', 'Tirupati', 'Kadapa'], 'Arunachal Pradesh': ['Naharlagun'], 'Assam': ['Sivasagar', 'Nalbari', 'Silchar', 'Guwahati', 'Byrnihat', 'Nagaon'], 'Bihar': ['Gaya', 'Saharsa', 'Motihari', 'Manguraha', 'Darbhanga', 'Purnia', 'Begusarai', 'Samastipur', 'Aurangabad', 'Muzaffarpur', 'Arrah', 'Bettiah', 'Patna', 'Bhagalpur', 'Hajipur', 'Munger', 'Chhapra', 'Araria', 'Siwan', 'Katihar', 'Bihar Sharif', 'Kishanganj', 'Rajgir', 'Sasaram', 'Buxar'], 'Chandigarh': ['Chandigarh'], 'Chhattisgarh': ['Raipur', 'Bilaspur', 'Korba', 'Chhal', 'Tumidih', 'Milupara', 'Kunjemura', 'Bhilai'], 'Delhi': ['Delhi'], 'Gujarat': ['Vatva', 'Nandesari', 'Gandhi Nagar', 'Ahmedabad', 'Ankleshwar', 'Surat', 'Vapi'], 'Haryana': ['Ambala', 'Kaithal', 'Jind', 'Sirsa', 'Palwal', 'Dharuhera', 'Manesar', 'Sonipat', 'Fatehabad', 'Narnaul', 'Yamunanagar', 'Gurugram', 'Bahadurgarh', 'Rohtak', 'Faridabad', 'Mandikhera', 'Hisar', 'Panchgaon', 'Bhiwani', 'Panchkula', 'Panipat', 'Charkhi Dadri', 'Ballabgarh', 'Karnal', 'Kurukshetra'], 'Himachal Pradesh': ['Baddi'], 'Jammu and Kashmir': ['Srinagar'], 'Jharkhand': ['Pathardih', 'Jorapokhar', 'Dhanbad'], 'Karnataka': ['Tumakuru', 'Bengaluru', 'Kolar', 'Mangalore', 'Mysuru', 'Kalaburagi', 'Hubballi', 'Koppal', 'Dharwad', 'Chikkamagaluru', 'Raichur', 'Gadag', 'Hassan', 'Karwar', 'Yadgir', 'Madikeri', 'Chikkaballapur', 'Vijayapura', 'Davanagere', 'Bagalkot', 'Ramanagara', 'Belgaum', 'Chamarajanagar', 'Bidar', 'Haveri', 'Shivamogga', 'Udupi'], 'Kerala': ['Eloor', 'Kozhikode', 'Thiruvananthapuram', 'Ernakulam', 'Thrissur', 'Kollam', 'Kannur', 'Kochi'], 'Madhya Pradesh': ['Maihar', 'Dewas', 'Pithampur', 'Ujjain', 'Ratlam', 'Jabalpur', 'Sagar', 'Katni', 'Bhopal', 'Mandideep', 'Satna', 'Indore', 'Damoh', 'Gwalior', 'Singrauli'], 'Maharashtra': ['Mira Bhayandar', 'Ahmednagar', 'Thane', 'Kalyan', 'Sangli', 'Pune', 'Badlapur', 'Aurangabad', 'Latur', 'Malegaon', 'Solapur', 'Navi Mumbai', 'Chandrapur', 'Nagpur', 'Jalna', 'Parbhani', 'Belapur', 'Akola', 'Nashik', 'Pimpri Chinchwad', 'Boisar', 'Virar', 'Nanded', 'Ulhasnagar', 'Bhiwandi', 'Mumbai', 'Dhule', 'Jalgaon', 'Amravati', 'Kolhapur', 'Mahad'], 'Manipur': ['Imphal'], 'Meghalaya': ['Shillong'], 'Mizoram': ['Aizawl'], 'Nagaland': ['Kohima'], 'Odisha': ['Brajrajnagar', 'Angul', 'Byasanagar', 'Rourkela', 'Barbil', 'Nayagarh', 'Tensa', 'Bileipada', 'Suakati', 'Cuttack', 'Talcher', 'Baripada', 'Keonjhar', 'Bhubaneswar', 'Rairangpur', 'Balasore'], 'Puducherry': ['Puducherry'], 'Punjab': ['Amritsar', 'Khanna', 'Ludhiana', 'Jalandhar', 'Mandi Gobindgarh', 'Bathinda', 'Rupnagar', 'Patiala'], 'Rajasthan': ['Jaisalmer', 'Udaipur', 'Sawai Madhopur', 'Dholpur', 'Bikaner', 'Jhalawar', 'Jaipur', 'Banswara', 'Pali', 'Sikar', 'Karauli', 'Hanumangarh', 'Bundi', 'Alwar', 'Nagaur', 'Churu', 'Chittorgarh', 'Barmer', 'Bhiwadi', 'Jhunjhunu', 'Jodhpur', 'Dausa', 'Tonk', 'Bhilwara', 'Bharatpur', 'Pratapgarh', 'Sirohi', 'Rajsamand', 'Dungarpur', 'Baran', 'Sri Ganganagar', 'Ajmer', 'Kota', 'Jalore'], 'Sikkim': ['Gangtok'], 'Tamil Nadu': ['Cuddalore', 'Gummidipoondi', 'Karur', 'Ramanathapuram', 'Vellore', 'Palkalaiperur', 'Tiruchirappalli', 'Thoothukudi', 'Kanchipuram', 'Hosur', 'Virudhunagar', 'Thanjavur', 'Namakkal', 'Ooty', 'Tiruppur', 'Tirunelveli', 'Ariyalur', 'Nagapattinam', 'Dindigul', 'Salem', 'Chengalpattu', 'Ranipet', 'Madurai', 'Coimbatore', 'Chennai', 'Pudukottai'], 'Telangana': ['Hyderabad'], 'Tripura': ['Agartala'], 'Uttar Pradesh': ['Meerut', 'Prayagraj', 'Lucknow', 'Kanpur', 'Jhansi', 'Firozabad', 'Ghaziabad', 'Greater Noida', 'NOIDA', 'Bulandshahr', 'Gorakhpur', 'Muzaffarnagar', 'Bareilly', 'Agra', 'Vrindavan', 'Varanasi', 'Baghpat', 'Khurja', 'Hapur', 'Moradabad'], 'Uttarakhand': ['Rishikesh', 'Kashipur', 'Dehradun'], 'West Bengal': ['Asansol', 'Barrackpore', 'Howrah', 'Kolkata', 'Durgapur', 'Haldia', 'Siliguri']}\n"
     ]
    }
   ],
   "source": [
    "state_area_dict = (\n",
    "    df.groupby('state')['area']\n",
    "      .apply(lambda x: list(set(x)))\n",
    "      .to_dict()\n",
    ")\n",
    "print(f'{state_area_dict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54647,
     "status": "ok",
     "timestamp": 1768851760309,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "jbUO2zrys7jo",
    "outputId": "8e8d8102-68a0-4309-8e19-fd897138f5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AQI for next 7 days in Delhi:\n",
      "[228.86156 228.1207  228.80872 229.01472 230.065   228.58365 229.41962]\n"
     ]
    }
   ],
   "source": [
    "#  predicting for Delhi\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "def get_area_data(df, state, area, lookback=30):\n",
    "    # Filter by state and area\n",
    "    data = df[(df['state'] == state) & (df['area'] == area)].copy()\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y')\n",
    "    data = data.sort_values('date')\n",
    "\n",
    "    # Resample to ensure daily continuity and handle missing values\n",
    "    data = data.set_index('date')['aqi_value'].resample('D').mean().interpolate()\n",
    "\n",
    "    if len(data) < lookback + 7:\n",
    "        raise ValueError(f\"Not enough data for {area}, {state} to create sequences.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# 2. Define the LSTM Model\n",
    "class AQILSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=7):\n",
    "        super(AQILSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        # Take the output of the last time step and pass through linear layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 3. Training Function\n",
    "def train_model(X, y, epochs=100, lr=0.01):\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    y_tensor = torch.FloatTensor(y)\n",
    "\n",
    "    model = AQILSTM()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_aqi(csv_path, state_name, area_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    series = get_area_data(df, state_name, area_name)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_series = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "    # Create Sequences (X: past 30 days, y: next 7 days)\n",
    "    lookback = 30\n",
    "    forecast = 7\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_series) - lookback - forecast + 1):\n",
    "        X.append(scaled_series[i : i + lookback])\n",
    "        y.append(scaled_series[i + lookback : i + lookback + forecast].flatten())\n",
    "\n",
    "    # Train\n",
    "    model = train_model(np.array(X), np.array(y))\n",
    "\n",
    "    # Predict for the next 7 days using the most recent 30 days\n",
    "    last_window = torch.FloatTensor(scaled_series[-lookback:]).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(last_window)\n",
    "        predictions = scaler.inverse_transform(pred_scaled.numpy()).flatten()\n",
    "\n",
    "    return predictions, series.values[-lookback:]\n",
    "\n",
    "state = \"Delhi\"\n",
    "area = \"Delhi\"\n",
    "forecast_values, history = predict_aqi('new_aqi.csv', state, area)\n",
    "\n",
    "print(f\"Predicted AQI for next 7 days in {area}:\")\n",
    "print(forecast_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106200,
     "status": "ok",
     "timestamp": 1768852599190,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "r43WjCPQxBId",
    "outputId": "5534383d-185c-49d8-f924-3a7cfedf2f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pre-trained model on Delhi...\n",
      "Epoch [50/200], Loss: 0.0274\n",
      "Epoch [100/200], Loss: 0.0198\n",
      "Epoch [150/200], Loss: 0.0186\n",
      "Epoch [200/200], Loss: 0.0179\n",
      "Model saved successfully to aqi_pretrained_model.pth\n"
     ]
    }
   ],
   "source": [
    "###  pre-training on delhi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1. Define the Model Architecture (Must be the same during saving and loading)\n",
    "class AQILSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=7):\n",
    "        super(AQILSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# 2. Preparation and Training Function\n",
    "def train_and_save_base_model(csv_path, state_name, area_name, save_path=\"aqi_pretrained_model.pth\"):\n",
    "    # Load Data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data = df[(df['state'] == state_name) & (df['area'] == area_name)].copy()\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y')\n",
    "    series = data.sort_values('date').set_index('date')['aqi_value'].resample('D').mean().interpolate()\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "    # Create Sequences (30 days lookback -> 7 days forecast)\n",
    "    lookback = 30\n",
    "    forecast = 7\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - lookback - forecast + 1):\n",
    "        X.append(scaled_data[i : i + lookback])\n",
    "        y.append(scaled_data[i + lookback : i + lookback + forecast].flatten())\n",
    "\n",
    "    X_train = torch.FloatTensor(np.array(X))\n",
    "    y_train = torch.FloatTensor(np.array(y))\n",
    "\n",
    "    # Initialize Model\n",
    "    model = AQILSTM(input_size=1, hidden_size=64, num_layers=2, output_size=7)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training Loop\n",
    "    print(f\"Training pre-trained model on {area_name}...\")\n",
    "    model.train()\n",
    "    for epoch in range(1000):  # Higher epochs for the base model\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/200], Loss: {loss.item():.4f}')\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved successfully to {save_path}\")\n",
    "\n",
    "# pre-training for other areas\n",
    "train_and_save_base_model('aqi.csv', 'Delhi', 'Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1768852711510,
     "user": {
      "displayName": "Shiv Gowda",
      "userId": "17010955676692746988"
     },
     "user_tz": -330
    },
    "id": "tL40IH6H0u3x",
    "outputId": "177f3d0d-aa3f-4728-b37a-d531c333c781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted AQI for the next 7 days:\n",
      "Day 1: 121.89\n",
      "Day 2: 123.14\n",
      "Day 3: 123.39\n",
      "Day 4: 127.36\n",
      "Day 5: 128.38\n",
      "Day 6: 128.14\n",
      "Day 7: 130.83\n"
     ]
    }
   ],
   "source": [
    "# predict for other area\n",
    "new_aqi= '../Dataset/new_aqi.csv'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "class AQILSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=7):\n",
    "        super(AQILSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def predict_new_area(model_path, csv_path, state_name, area_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data = df[(df['state'] == state_name) & (df['area'] == area_name)].copy()\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y')\n",
    "\n",
    "    series = data.sort_values('date').set_index('date')['aqi_value'].resample('D').mean().interpolate()\n",
    "\n",
    "    if len(series) < 30:\n",
    "        raise ValueError(\"Need at least 30 days of historical data for this area.\")\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "    input_window = torch.FloatTensor(scaled_data[-30:]).unsqueeze(0)\n",
    "    model = AQILSTM()\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction_scaled = model(input_window)\n",
    "\n",
    "\n",
    "    prediction_actual = scaler.inverse_transform(prediction_scaled.numpy()).flatten()\n",
    "\n",
    "    return prediction_actual\n",
    "\n",
    "try:\n",
    "    forecast = predict_new_area('../Model/aqi_pretrained_model.pth', new_aqi, 'Maharashtra', 'Mumbai')\n",
    "\n",
    "    print(\"Predicted AQI for the next 7 days:\")\n",
    "    for i, val in enumerate(forecast, 1):\n",
    "        print(f\"Day {i}: {val:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= BASELINE METRICS (NO CALIBRATION) =========\n",
      "Day-1: RMSE = 35.6, ±10 AQI Accuracy = 23.7%\n",
      "Day-2: RMSE = 36.3, ±10 AQI Accuracy = 24.0%\n",
      "Day-3: RMSE = 35.8, ±10 AQI Accuracy = 24.9%\n",
      "Day-4: RMSE = 36.4, ±10 AQI Accuracy = 26.0%\n",
      "Day-5: RMSE = 37.0, ±10 AQI Accuracy = 24.8%\n",
      "Day-6: RMSE = 37.0, ±10 AQI Accuracy = 23.0%\n",
      "Day-7: RMSE = 39.0, ±10 AQI Accuracy = 20.5%\n",
      "\n",
      "AQI Category Precision (Day-1): 0.72\n",
      "\n",
      "========= CALIBRATED METRICS (EXPONENTIAL DECAY) =========\n",
      "Day-1: RMSE = 40.9, Improvement = -14.7%\n",
      "Day-3: RMSE = 35.5, Improvement = 0.9%\n",
      "Day-7: RMSE = 36.1, Improvement = 7.3%\n",
      "\n",
      "========= CALIBRATED PRECISION METRICS =========\n",
      "Day-1 Calibrated Precision: 0.686\n",
      "Day-3 Calibrated Precision: 0.711\n",
      "Day-7 Calibrated Precision: 0.712\n",
      "\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, precision_score\n",
    "\n",
    "# ---------------------------\n",
    "# 1. MODEL ARCHITECTURE\n",
    "# ---------------------------\n",
    "class AQILSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2, output_size=7):\n",
    "        super(AQILSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# ---------------------------\n",
    "# 2. UTILITY FUNCTIONS\n",
    "# ---------------------------\n",
    "def aqi_category(aqi):\n",
    "    if aqi <= 50: return 0    # Good\n",
    "    elif aqi <= 100: return 1 # Satisfactory\n",
    "    elif aqi <= 200: return 2 # Moderate\n",
    "    elif aqi <= 300: return 3 # Poor\n",
    "    elif aqi <= 400: return 4 # Very Poor\n",
    "    else: return 5            # Severe\n",
    "\n",
    "def apply_exponential_calibration(preds, actuals, alpha=0.6):\n",
    "    calibrated = preds.copy()\n",
    "    for i in range(1, len(preds)):\n",
    "        error = actuals[i - 1] - preds[i - 1]\n",
    "        calibrated[i] = preds[i] + alpha * error\n",
    "    return calibrated\n",
    "\n",
    "def get_area_data(df, state, area, lookback=30):\n",
    "    data = df[(df['state'] == state) & (df['area'] == area)].copy()\n",
    "    data['date'] = pd.to_datetime(data['date'], format='%d-%m-%Y')\n",
    "    data = data.sort_values('date')\n",
    "    series = data.set_index('date')['aqi_value'].resample('D').mean().interpolate()\n",
    "    return series\n",
    "\n",
    "# ---------------------------\n",
    "# 3. METRIC EVALUATION FUNCTION\n",
    "# ---------------------------\n",
    "def evaluate_model(model, X_test, y_test, scaler, tolerance=10, alpha=0.6):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test).cpu().numpy()\n",
    "\n",
    "    # Inverse scaling to return to actual AQI values\n",
    "    preds_real = scaler.inverse_transform(preds)\n",
    "    y_real = scaler.inverse_transform(y_test.cpu().numpy())\n",
    "\n",
    "    horizon = preds_real.shape[1]\n",
    "\n",
    "    print(\"\\n========= BASELINE METRICS (NO CALIBRATION) =========\")\n",
    "    baseline_rmses = []\n",
    "    \n",
    "    for day in range(horizon):\n",
    "        rmse = np.sqrt(mean_squared_error(y_real[:, day], preds_real[:, day]))\n",
    "        baseline_rmses.append(rmse)\n",
    "        accuracy = np.mean(np.abs(y_real[:, day] - preds_real[:, day]) <= tolerance)\n",
    "        print(f\"Day-{day+1}: RMSE = {rmse:.1f}, ±{tolerance} AQI Accuracy = {accuracy*100:.1f}%\")\n",
    "\n",
    "    # Baseline Precision (Day 1)\n",
    "    true_cat_day1 = [aqi_category(val) for val in y_real[:, 0]]\n",
    "    pred_cat_day1 = [aqi_category(val) for val in preds_real[:, 0]]\n",
    "    precision_base = precision_score(true_cat_day1, pred_cat_day1, average=\"weighted\", zero_division=0)\n",
    "    print(f\"\\nAQI Category Precision (Day-1): {precision_base:.2f}\")\n",
    "\n",
    "    print(\"\\n========= CALIBRATED METRICS (EXPONENTIAL DECAY) =========\")\n",
    "    calibrated_preds = np.zeros_like(preds_real)\n",
    "    for day in range(horizon):\n",
    "        calibrated_preds[:, day] = apply_exponential_calibration(\n",
    "            preds_real[:, day], y_real[:, day], alpha=alpha\n",
    "        )\n",
    "\n",
    "    # Reporting specific days as requested\n",
    "    report_days = [0, 2, 6] # Day 1, 3, 7\n",
    "    for day in report_days:\n",
    "        if day < horizon:\n",
    "            rmse_cal = np.sqrt(mean_squared_error(y_real[:, day], calibrated_preds[:, day]))\n",
    "            improvement = (1 - rmse_cal / baseline_rmses[day]) * 100\n",
    "            print(f\"Day-{day+1}: RMSE = {rmse_cal:.1f}, Improvement = {improvement:.1f}%\")\n",
    "\n",
    "    print(\"\\n========= CALIBRATED PRECISION METRICS =========\")\n",
    "    for day in report_days:\n",
    "        if day < horizon:\n",
    "            true_cat = [aqi_category(val) for val in y_real[:, day]]\n",
    "            cal_cat = [aqi_category(val) for val in calibrated_preds[:, day]]\n",
    "            precision_cal = precision_score(true_cat, cal_cat, average=\"weighted\", zero_division=0)\n",
    "            print(f\"Day-{day+1} Calibrated Precision: {precision_cal:.3f}\")\n",
    "\n",
    "    print(\"\\n===============================================\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4. EXECUTION FLOW\n",
    "# ---------------------------\n",
    "# Configuration - Adjust paths if necessary\n",
    "CSV_PATH = '../Dataset/new_aqi.csv' \n",
    "MODEL_PATH = '../Model/aqi_pretrained_model.pth' # Generated from cell In[9] of your notebook\n",
    "\n",
    "try:\n",
    "    # Prepare Data (Example using Delhi as per notebook)\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    series = get_area_data(df, \"Delhi\", \"Delhi\")\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_series = scaler.fit_transform(series.values.reshape(-1, 1))\n",
    "\n",
    "    lookback, forecast = 30, 7\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_series) - lookback - forecast + 1):\n",
    "        X.append(scaled_series[i : i + lookback])\n",
    "        y.append(scaled_series[i + lookback : i + lookback + forecast].flatten())\n",
    "\n",
    "    X_test_tensor = torch.FloatTensor(np.array(X))\n",
    "    y_test_tensor = torch.FloatTensor(np.array(y))\n",
    "\n",
    "    # Initialize and Load Model\n",
    "    model = AQILSTM()\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))\n",
    "\n",
    "    # Run Evaluation\n",
    "    evaluate_model(model, X_test_tensor, y_test_tensor, scaler)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Ensure '{CSV_PATH}' and '{MODEL_PATH}' exist in the directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuTztT1Jx8xEeVAOfuFOmO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
